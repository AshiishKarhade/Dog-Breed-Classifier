# -*- coding: utf-8 -*-
"""Totality Corp - Dog Breed Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hTxRtV4UWU2usY5rfJIQ6sgqE7GKvVrn

## Dog Breed Classification : Totality Corp Assignment

### Part-1: Build a dog breed image classification model with the architecture specified below. ​

- The classifier should only predict scores for these breeds : beagle, chihuahua, doberman, french_bulldog, golden_retriever, malamute, pug, saint_bernard, scottish_deerhound, tibetan_mastiff.
Any of these frameworks can be used : Tensorflow, Keras, Pytorch, Caffee.
- The classifier should only be built using Resnet50 CNN architecture.
Evaluation metrics i.e Accuracy, Confusion Matrix, F1 Score, ROC-AUC Score shall be calculated
on test data.
- The entire process should be clearly logged in a Jupyter Notebook and uploaded to a public github repo, the exact link to this notebook is to be submitted as a result of this assignment.

Dataset​ - ​https://www.kaggle.com/c/dog-breed-identification/data
"""

!pip install opendatasets --quiet
import opendatasets as od
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import AveragePooling2D, Dense, Flatten, Dropout
from keras.applications import ResNet50
from keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, accuracy_score, auc,roc_curve, plot_roc_curve
import seaborn as sns
from PIL import Image

"""#### Downloading the Dataset"""

# DOWNLOAD AND UNZIP THE DATASET FROM KAGGLE
DATASET_URL = 'https://www.kaggle.com/c/dog-breed-identification/data'
od.download(DATASET_URL)
!unzip -q /content/dog-breed-identification/dog-breed-identification.zip

TRAIN_PATH = '/content/train'
TEST_PATH = '/content/test'

"""#### Data Preparation and Cleaning"""

# Loading the CSV file
df = pd.read_csv('/content/labels.csv')
df.head()

# shape of our labes.csv
print(df.shape)

# Adjusting the labels.csv to feed into our Keras ImageDataGenerators
df['id'] = df['id'] + '.jpg'
df.head()

dog_categories = ['beagle', 'chihuahua', 'doberman', 'french_bulldog', 'golden_retriever', 'malamute', 'pug', 'saint_bernard', 'scottish_deerhound', 'tibetan_mastiff']
len(dog_categories)

train_datagen = ImageDataGenerator(
    #rescale=1./255,
    validation_split=0.1,
    rotation_range=25,
	zoom_range=0.1,
	width_shift_range=0.1,
	height_shift_range=0.1,
	shear_range=0.2,
	horizontal_flip=True,
)

train_generator = train_datagen.flow_from_dataframe(
    dataframe=df, 
    directory=TRAIN_PATH, 
    x_col='id', 
    y_col='breed', 
    target_size=(512, 512), 
    class_mode='categorical', 
    classes=dog_categories,
    subset='training')

val_generator = train_datagen.flow_from_dataframe(
    dataframe=df, 
    directory=TRAIN_PATH, 
    x_col='id', 
    y_col='breed', 
    target_size=(512, 512), 
    class_mode='categorical', 
    classes=dog_categories,
    subset='validation')

print(train_generator.class_indices)

"""#### Preparation of ResNet50 Model"""

resnet = ResNet50(
    include_top=False,
    weights="imagenet",
    input_shape=(512,512, 3)
)

#print(resnet.summary())

head = resnet.output
head = AveragePooling2D(pool_size=(7, 7))(head)
head = Flatten(name="flatten")(head)
head = Dense(256, activation="relu")(head)
head = Dropout(0.25)(head)
head = Dense(10, activation="softmax")(head)

model = Model(inputs=resnet.input, outputs=head)

model.summary()

for layer in resnet.layers:
	layer.trainable = False

# lr_schedule = keras.optimizers.schedules.ExponentialDecay(
#     initial_learning_rate=1e-2,
#     decay_steps=10000,
#     decay_rate=0.9)
# optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)

opt = Adam(learning_rate=0.0001)
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])

"""#### ResNet50 Model Training"""

batch_size = 64
nbEpochs = 20

history = model.fit(train_generator, 
                    steps_per_epoch = train_generator.samples // batch_size,
                    validation_data=val_generator, 
                    validation_steps = val_generator.samples // batch_size,
                    epochs = nbEpochs)

print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
#plt.show()
plt.savefig('accuracy.png')

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper right')
plt.show()
plt.savefig('loss.png')

model.save('final_model.h5')

"""#### Metrics"""

#Accuracy, Confusion Matrix, F1 Score, ROC-AUC Score shall be calculated on test data.

y_true = val_generator.classes
vals = val_generator.filepaths

y_preds = []
y_scores = []
for fpath in vals:
    img = Image.open(fpath)
    img = img.resize((512, 512))
    img = np.array(img)
    img = img.reshape(-1, 512, 512, 3)
    pros = model.predict(img)
    y_scores.append(pros)
    pros = np.argmax(pros)
    y_preds.append(pros)
y_scores = np.array(y_scores)
y_scores = y_scores.reshape((84, 10))

"""Classification Report"""

print(classification_report(y_true, y_preds))

"""Accuracy Score"""

asc = accuracy_score(y_true, y_preds)
print(f"ACCURACY SCORE : {asc}")

"""F1 Score"""

f1 = f1_score(y_true, y_preds, average='macro')
print(f"F1-SCORE : {f1}")

"""ROC AUC SCORE"""

roc_auc_score(y_true, y_scores, multi_class='ovo')

"""Confusion Matrix"""

cm = confusion_matrix(y_true, y_preds)
df_cm = pd.DataFrame(cm, index = dog_categories, columns = dog_categories)
plt.figure(figsize = (8,5))
hp = sns.heatmap(df_cm, annot=True, cmap='Blues')

"""### Part - 2:​ ( Extra brownie points! )

- Build an API around the model inference pipeline which takes in an Input image in Base64 and responds with the appropriate dog breed. Any framework of choice can be used but the API needs to follow REST architecture and shall be deployed publicly for us to test.

- The input format needs to be :
```
{
image : <base64 encoded image> 
}
```

- Expected response:
```
{
breed : <resulting label>
score : <prediction score of the above label > 
}
```

- A working api endpoint needs to be submitted as a result of this assignment.
"""

